<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[码农的耕地]]></title>
  <subtitle><![CDATA[夕阳下，烟柳树，coding]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="http://yoursite.com/"/>
  <updated>2016-05-31T05:00:02.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name><![CDATA[cbf]]></name>
    <email><![CDATA[xmucbf@gmail.com]]></email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[JVM优化的几个原则]]></title>
    <link href="http://yoursite.com/2016/05/31/JVM%E4%BC%98%E5%8C%96%E7%9A%84%E5%87%A0%E4%B8%AA%E5%8E%9F%E5%88%99/"/>
    <id>http://yoursite.com/2016/05/31/JVM优化的几个原则/</id>
    <published>2016-05-31T04:34:33.000Z</published>
    <updated>2016-05-31T05:00:02.000Z</updated>
    <content type="html"><![CDATA[<ol>
<li>minor gc回收原则：每次minor gc尽量多的回收垃圾对象</li>
<li>GC内存最大化原则：堆空间越大、垃圾回收效果越好</li>
<li>吞吐量、延迟、内存占用，三选二进行调优<h3 id="默认的配置："><a href="#默认的配置：" class="headerlink" title="默认的配置："></a>默认的配置：</h3>-Xms350m<br>-Xmx750m<br>-XX:MaxPermSize=350m<br>-XX:ReservedCodeCacheSize=96m<br>-ea<br>-Dsun.io.useCanonCaches=false<br>-Djava.net.preferIPv4Stack=true<br>-XX:+UseCodeCacheFlushing<br>-XX:+UseConcMarkSweepGC<br>-XX:SoftRefLRUPolicyMSPerMB=50<br>-Dawt.useSystemAAFontSettings=lcd<h3 id="修改的第一版本配置："><a href="#修改的第一版本配置：" class="headerlink" title="修改的第一版本配置："></a>修改的第一版本配置：</h3>-Xms750m<br>-Xmx750m<br>-XX:PermSize=350m<br>-XX:MaxPermSize=350m<br>-XX:ReservedCodeCacheSize=96m<br>-XX:+PrintGCTimeStamps<br>-XX:+PrintGCDetails<br>-Xloggc:/tmp/idea.log<br>-ea<br>-Dsun.io.useCanonCaches=false<br>-Djava.net.preferIPv4Stack=true<br>-XX:+UseCodeCacheFlushing<br>-XX:+UseConcMarkSweepGC<br>-XX:SoftRefLRUPolicyMSPerMB=50<br>-Dawt.useSystemAAFontSettings=lcd</li>
</ol>
<h2 id="一-内存大小的调整"><a href="#一-内存大小的调整" class="headerlink" title="一:内存大小的调整"></a>一:内存大小的调整</h2><h3 id="gc-日志分析"><a href="#gc-日志分析" class="headerlink" title="gc 日志分析"></a>gc 日志分析</h3><p>完整的gc日志：<br>1406.535: [GC 1406.535: [ParNew: 51390K-&gt;958K(57536K), 0.0176440 secs] 421864K-&gt;371433K(761664K), 0.0178630 secs] [Times: user=0.02 sys=0.00, real=0.01 secs]</p>
<ol>
<li>GC 1406.535:触发的是minor gc 时间点是jvm启动到现在的时间：1406.535</li>
<li>[ParNew: 51390K-&gt;958K(57536K), 0.0176440 secs]：新生代大小是57536，使用的是ParNew算法，从51390K降低到了958K。消耗的时间是：0.0176440秒。回收了50432 ，同时也告诉了我们survivor大小是958K</li>
<li>421864K-&gt;371433K(761664K), 0.0178630 secs : 总共的堆大小是761664，一次minor gc后从421864降到了371433，降低的是50431,也就是说有1k的数据从新生代进入了老生代。但是老生代大小没有发生变化，估计是它自己计算错误了。</li>
<li>[Times: user=0.02 sys=0.00, real=0.01 secs]:用户态消耗的时间是：0.02 系统态消耗的时间：0.00，实际消耗的时间0.01<br>从上面数据可以看出堆大小：761664K(743M) 新生代：57536K(56M) 老生代：704128K(687M)<br>看一次fullgc的情况<br>20.837: [Full GC (System) 20.837: [CMS: 109217K-&gt;80428K(704128K), 0.5815740 secs] 126205K-&gt;80428K(761664K), [CMS Perm : 113263K-&gt;113166K(358400K)], 0.5817070 secs] [Times: user=0.57 sys=0.02, real=0.58 secs]</li>
<li>[CMS: 109217K-&gt;80428K(704128K), 0.5815740 secs]:老生代大小从109217K降到了80428K，总共大小是704128K。之后就再也没有发生full gc,也就是说活跃的数据是80428K</li>
<li>[CMS Perm : 113263K-&gt;113166K(358400K)；持久代的大小是358400K，活跃的数据是113166K<br>再看看一些gc情况：<br>zhaoming@zhaoming:~$ jstat -gcutil 4943 5000 1000<br>S0     S1     E      O      P     YGC     YGCT    FGC    FGCT     GCT<br>2.07   0.00  73.92  77.17  64.03    646   15.361     3    0.628   15.989<br>2.07   0.00  84.31  77.17  64.03    646   15.361     3    0.628   15.989<br>2.07   0.00  93.63  77.17  64.03    646   15.361     3    0.628   15.989<br>0.00   2.15   4.29  77.17  64.03    647   15.393     3    0.628   16.020<br>一直发生的是minor gc没有发生full gc的情况了。<h3 id="上面的数据分析"><a href="#上面的数据分析" class="headerlink" title="上面的数据分析"></a>上面的数据分析</h3></li>
<li>老生代总大小：704128K(687M),堆大小：761664K(743M),新生代：57536K(56M)</li>
<li>老生代活跃数据大小：80428K,因为整个日志上看，只发生了一次full gc</li>
<li>垃圾回收器是CMS</li>
</ol>
<h3 id="内存大小设置："><a href="#内存大小设置：" class="headerlink" title="内存大小设置："></a>内存大小设置：</h3><h3 id="优化原则一"><a href="#优化原则一" class="headerlink" title="优化原则一"></a>优化原则一</h3><ol>
<li>-Xmx和-Xms设置为活跃数据大小的3~4倍   这里就是80428的3~4倍(235m~~314M),当前设置的是750M,应该是有余的</li>
<li>PermSize和MaxPermSize设置为活跃数据大小的1.2~1.5倍(93M~~117M) ,当前也是有余的</li>
<li>新生代设置为活跃数据大小的1~1.5倍(78m~~117m),这里默认的新生代大小是不够的，我们可以提升下。</li>
</ol>
<h2 id="二-调优延迟-响应性-–总纲"><a href="#二-调优延迟-响应性-–总纲" class="headerlink" title="二 调优延迟/响应性 –总纲"></a>二 调优延迟/响应性 –总纲</h2><ol>
<li>测量minor gc的持续时间</li>
<li>统计minor的次数</li>
<li>测量Full gc的最差持续时间</li>
<li>统计最差情况下，Full gc的频率</li>
</ol>
<h2 id="三-调优延迟-响应性-–新生代"><a href="#三-调优延迟-响应性-–新生代" class="headerlink" title="三 调优延迟/响应性 –新生代"></a>三 调优延迟/响应性 –新生代</h2><p>-Xmn120m  – 发生改变的数据<br>-Xms750m<br>-Xmx750m<br>-XX:PermSize=350m<br>-XX:MaxPermSize=350m<br>-XX:ReservedCodeCacheSize=96m<br>-XX:+PrintGCTimeStamps<br>-XX:+PrintGCDetails<br>-Xloggc:/tmp/idea.log<br>-ea<br>-Dsun.io.useCanonCaches=false<br>-Djava.net.preferIPv4Stack=true<br>-XX:+UseCodeCacheFlushing<br>-XX:+UseConcMarkSweepGC<br>-XX:SoftRefLRUPolicyMSPerMB=50<br>-Dawt.useSystemAAFontSettings=lcd<br>开idea，启用tomcat，发现还是没有fullgc，说明idea中大量的对象都是朝生夕死，活跃数据很稳定。<br>2014-04-08T20:39:27.207+0800: 243.821: [GC 243.822: [ParNew: 110592K-&gt;10359K(110592K), 0.0855940 secs] 351176K-&gt;259675K(755712K), 0.0860110 secs] [Times: user=0.08 sys=0.01, real=0.09 secs]<br>2014-04-08T20:39:29.575+0800: 246.189: [GC 246.189: [ParNew: 108663K-&gt;4195K(110592K), 0.0203700 secs] 357979K-&gt;253512K(755712K), 0.0209180 secs] [Times: user=0.04 sys=0.00, real=0.02 secs]<br>2014-04-08T20:39:33.517+0800: 250.131: [GC 250.131: [ParNew: 102499K-&gt;8590K(110592K), 0.0742860 secs] 351816K-&gt;257907K(755712K), 0.0746160 secs] [Times: user=0.10 sys=0.01, real=0.07 secs]<br>2014-04-08T20:39:35.489+0800: 252.103: [GC 252.103: [ParNew: 106894K-&gt;12288K(110592K), 0.0735800 secs] 356211K-&gt;263572K(755712K), 0.0738440 secs] [Times: user=0.10 sys=0.01, real=0.07 secs]<br>平均gc的时间是 0.05s，若是你要求的gc时间是0.04，那么减少新生代，若是要求的时间是0.08s，那么可以扩大一点新生代，在保持总大小不变的情况下，增加或是减少10%的大小。<br>平均的gc频率是2.5s左右，若是你期望的是5s，填充完2048M的新生代需要2.5s，那么要5s的话2048*(5/2.5) = 4096m，这个时候需要扩大新生代的内存大小，总的大小都需要增加2048m</p>
<h3 id="优化原则二-–-新生代"><a href="#优化原则二-–-新生代" class="headerlink" title="优化原则二 – 新生代"></a>优化原则二 – 新生代</h3><ol>
<li>老年代空间不应该小于活跃数据的1.5倍</li>
<li>新生代空间至少为java堆大小的10%.通过-Xmx和-Xms可以设置</li>
<li>增大java堆大小时候，不能超过物理堆大小<br>tips：吞吐量和延迟考虑的话 -Xms、-Xmx设置为相同。只有在两者相同的情况下，设置-Xmn才有意义。不然可以通过-XX:MaxNewSize、-XX:NewSize两个参数来设置新生代的大小。</li>
</ol>
<h2 id="二-调优延迟-响应性-–老生代"><a href="#二-调优延迟-响应性-–老生代" class="headerlink" title="二 调优延迟/响应性 –老生代"></a>二 调优延迟/响应性 –老生代</h2><p>若是老生代大小是4096m，活跃数据是1370m，那么空闲数据是2726，minor gc每次提升的数据是21m，minor gc的频率是2.147s，那么每秒提升的数据是21494/2.147 = 10011kb/s，那么填充满2726，需要2726/10 = 272.6s 大约4.5分钟。<br>若是你的full gc时间间隔大于这个数值，那么老生代的大小是可以的，若是小于这个数据，就需要增加老生代的大小了。</p>
<h2 id="二-调优延迟-响应性-–-cms调优"><a href="#二-调优延迟-响应性-–-cms调优" class="headerlink" title="二 调优延迟/响应性 – cms调优"></a>二 调优延迟/响应性 – cms调优</h2><ol>
<li>full gc时候一定会触发一次minor gc，除非你设置了 -XX:ScavengeBeforeFull选项 。</li>
<li>因为是并行的收集，延迟性会有提升</li>
<li>压缩式的gc，就是内存碎片整理会消耗大量的时间</li>
</ol>
<p>几个关键点</p>
<ol>
<li>新生代提升到老生代的速率</li>
<li>并行回收老生代空间的速率</li>
<li>老生代的碎片化空间</li>
</ol>
<p>解决第三个问题的手段</p>
<ol>
<li>足够大的内存，减少stop-the-world的压缩</li>
<li>降低从新生代提升到老生代的速率<br>-XX:SurvivorRatio=8 参数调整<br>在保持新生代大小不变的情况下，增加survivor的大小  -&gt; eden 变小 —&gt; minor gc 变的频繁，那么在满足minor gc的要求下，那么必须保持eden不变，增大整个新生代。<br>增大survivor会加长对象在新生代的时间，但是会加快minor gc的频率<br>晋升阀值的计算依据于每次minor gc后存活的对象同目标survivor空间占用的空间大小。<br>具体通过<blockquote>
<p>-XX:+PrintTenuringDistribution  打印对象的年龄<br>2014-04-18T18:23:38.843+0800: 67.444: [GC 67.444: [ParNew<br>Desired survivor size 6291456 bytes, new threshold 1 (max 4)<br>- age   1:    6792744 bytes,    6792744 total<br>- age   2:    2366824 bytes,    9159568 total<br>- age   3:    1924344 bytes,   11083912 total</p>
</blockquote>
</li>
</ol>
<p>内部计算的晋升阀值是：1.<br>最大晋升阀值是4，第一次  阀值是通过-XX:MaxTenuringThreshold=n来设置的。在JDK1.6.6版本后，范围是在1~15之间。JDK5中范围是1~31.<br>survivor的空间大小乘以目标存活率得到的大小：6291456<br>目标存活率是：预计空间目标在survivor空间中占有的百分比。JVM在GC之后忍让维持的survivor空间占用，通过-XX:TargetsurivorRatio=50来设置，默认是50，这个数值是经过大量的测试得出的，一般不需要修改。<br>当survivor空间的使用小于或是等于JVM期望维护的数值时，会将最大晋升阀值作为计算的晋升阀值。若是JVM觉得无法维持survivor空间的占有时候，会使用一个低于最大晋升阀值的数值来保证survivor空间的占用。<br>当存活的对象大小大于survivor空间的时候，会加速提升对象到老生代的速度。<br>看两个例子:</p>
<blockquote>
<p>2014-04-18T18:23:38.843+0800: 67.444: [GC 67.444: [ParNew<br>Desired survivor size 6291456 bytes, new threshold 1 (max 4)<br>- age   1:    6792744 bytes,    6792744 total<br>- age   2:    2366824 bytes,    9159568 total<br>- age   3:    1924344 bytes,   11083912 total`</p>
</blockquote>
<p>因为留存的对象大小是11083912，远大于计算预估的的大小6291456，所以需要降低晋升阀值，加快进入老生代的速率，故是1 ，最大是4.若是一直保持这种状态下，那么需要增加survivor空间。</p>
<blockquote>
<p>2014-04-18T18:43:50.378+0800: 1278.979: [GC 1278.980: [ParNew<br>Desired survivor size 6291456 bytes, new threshold 4 (max 4)<br>- age   1:      72032 bytes,      72032 total<br>- age   2:       1408 bytes,      73440 total<br>- age   3:       1352 bytes,      74792 total</p>
</blockquote>
<p>留存的对象大小是74792，小于预计的大小6291456，若是对于晋升的阀值是最大，其实可以加大阀值的数值，将4增大，最大可到15.<br>若是minor gc的持续时间过长，那么就是新生代过大，需要调整下大小。<br>老生代的调优<br>老生代在回收的时候可能会发生并发回收失败，那么因为在回收的时候，有新的数据产生，老生代空间不够来进行回收了。那么可以通过两个参数来进行设置<br>-XX:+UseCMSInitiatingOccupancyOnly 使用手工设置的大小<br>-XX:CMSInitiatingOccupancyFaction  在老生代内存达到多少百分比时候进行回收。这个参数依赖于前面那个参数，若是不设置UseCMSInitiatingOccupancyOnly，只在第一次按照CMSInitiatingOccupancyFaction设置的值来进行回收，第二次还是自我调节的去回收<br>CMSInitiatingOccupancyFaction这个数值的大小必须大于活跃数据的大小，若是活跃数据是350，老生代是1024，那么他们之间的比例是350，那么CMSInitiatingOccupancyFaction必须大于350/1024.<br>CMSInitiatingOccupancyFaction这个值看是否设置合适就在于<br>cms-initial-mark   stop-world<br>cms-concurrent-mark<br>cms-concurrent-preclean<br>cms-concurrent-abortable-preclean<br>cms-remark         stop-world<br>cms-concurrent-sweep<br>cms-concurrent-reset<br>这几个阶段之间数值是否变化的不大，若是变化不大的话，那么说明CMSInitiatingOccupancyFaction这个值设置的太小了。<br>若是cms-initial-mark后直接出现full gc，那么说明CMSInitiatingOccupancyFaction设置的太大了。</p>
<p>持久代的回收<br>-XX:+CMSPermGenSweepingEnabled<br>-XX:CMSInitiatingPermOccupancyFraction<br>-XX:+CMSClassUnloadingEnabled<br>-XX:+CMSParallelRemarkEnabled<br>几个参数来设置</p>
]]></content>
    <summary type="html">
    <![CDATA[<ol>
<li>minor gc回收原则：每次minor gc尽量多的回收垃圾对象</li>
<li>GC内存最大化原则：堆空间越大、垃圾回收效果越好</li>
<li>吞吐量、延迟、内存占用，三选二进行调优<h3 id="默认的配置："><a href="#默认的配置：" c]]>
    </summary>
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
      <category term="jvm调优" scheme="http://yoursite.com/tags/jvm%E8%B0%83%E4%BC%98/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[性能定位整体思路]]></title>
    <link href="http://yoursite.com/2016/05/31/%E6%80%A7%E8%83%BD%E5%AE%9A%E4%BD%8D%E6%95%B4%E4%BD%93%E6%80%9D%E8%B7%AF/"/>
    <id>http://yoursite.com/2016/05/31/性能定位整体思路/</id>
    <published>2016-05-30T16:13:08.000Z</published>
    <updated>2016-05-31T04:55:15.000Z</updated>
    <content type="html"><![CDATA[<p>一个请求从客户端发起到最后在数据库中进行查询，中间经历了很多个环节。本文就是针对出现的问题，快速定位到是哪个步骤环节出现了问题，由于笔者也在不断的学习中，希望有问题大家能提出来共同进行学习。</p>
<h2 id="一、服务器定位"><a href="#一、服务器定位" class="headerlink" title="一、服务器定位"></a>一、服务器定位</h2><p>对于一般的应用，最常用的架构是：<br>客户端——nginx——tomcat等应用服务器——数据库/Memcache/redis。<br><img src="/2016/05/31/性能定位整体思路/1.png" alt="整体架构图" title="整体架构图"><br>下图是一个定位问题的结构图（盗图）。一般先从客户端入手，查看客户端的TPS和响应时间。如果TPS过低或者响应时间过长，可以查看一下客户端是否有错误日志产生，从错误日志中定位问题，若没有错误日志可以从堆栈信息中定位问题，详见下文的1.1.3节；如果TPS和响应时间都正常就可以查看一下客户端的资源利用率的使用情况，详见下文的1.2节。<br><img src="/2016/05/31/性能定位整体思路/2.png" alt="整体流程图" title="整体流程图"></p>
<h3 id="1-1-接口测试"><a href="#1-1-接口测试" class="headerlink" title="1.1 接口测试"></a>1.1 接口测试</h3><h4 id="1-1-1-接口的TPS和响应时间"><a href="#1-1-1-接口的TPS和响应时间" class="headerlink" title="1.1.1 接口的TPS和响应时间"></a>1.1.1 接口的TPS和响应时间</h4><p>在一般的接口测试，可以使用loadrunner或者在可以在测试机上安装grinder客户端，然后运行脚本，在log中可以看到本次执行的接口响应时间和TPS，如下图所示；<br><img src="/2016/05/31/性能定位整体思路/3.png" alt="TPS图" title="TPS图"></p>
<h4 id="1-1-2-查看错误日志"><a href="#1-1-2-查看错误日志" class="headerlink" title="1.1.2 查看错误日志"></a>1.1.2 查看错误日志</h4><p>查看是否有error日志，从error中获取信息，例如下图从测试客户端的error日志中查看到的错误信息：<br><img src="/2016/05/31/性能定位整体思路/4.png" alt="errorlog图" title="errorlog图"><br>错误日志中会有错误说明和错误的提示信息，可以从中获取到定位问题的方法，例如图示中的错误提示为：“A JSONObject text must begin with ‘{‘ at character 1”表示JSON对象的格式不对，可以参考代码做相应的修改。</p>
<h4 id="1-1-3-查看堆栈信息"><a href="#1-1-3-查看堆栈信息" class="headerlink" title="1.1.3 查看堆栈信息"></a>1.1.3 查看堆栈信息</h4><p>在运行的机器中，先用top命令获取进程的PID，然后用命令jstack + PID即可获取该进程号对应的java堆栈信息；获取到的堆栈信息需要先关注其线程状态state：</p>
<ul>
<li>死锁，Deadlock（重点关注）</li>
<li>执行中，Runnable</li>
<li>等待资源，Waiting on condition（重点关注）</li>
<li>等待获取监视器，Waiting on monitor entry（重点关注）</li>
<li>暂停，Suspended</li>
<li>对象等待中，Object.wait() 或 TIMED_WAITING</li>
<li>阻塞，Blocked（重点关注）</li>
<li>停止，Parked</li>
</ul>
<p>实例一：Waiting to lock 和 Blocked<br><img src="/2016/05/31/性能定位整体思路/5.png" alt="lock图" title="lock图"></p>
<ol>
<li>线程状态是 Blocked，阻塞状态。说明线程等待资源超时！</li>
<li>“ waiting to lock <0x00000000acf4d0c0>”指，线程在等待给这个 0x00000000acf4d0c0 地址上锁（英文可描述为：trying to obtain  0x00000000acf4d0c0 lock）。</0x00000000acf4d0c0></li>
<li>在 dump 日志里查找字符串 0x00000000acf4d0c0，发现有大量线程都在等待给这个地址上锁。如果能在日志里找到谁获得了这个锁（如locked &lt; 0x00000000acf4d0c0 &gt;），就可以顺藤摸瓜了。</li>
<li>“waiting for monitor entry”说明此线程通过 synchronized(obj) {……} 申请进入了临界区，从而进入了“Entry Set”队列，但该 obj 对应的 monitor 被其他线程拥有，所以本线程在 Entry Set 队列中等待。</li>
<li>第一行里，”RMI TCP Connection(267865)-172.16.5.25”是 Thread Name 。tid指Java Thread id。nid指native线程的id。prio是线程优先级。[0x00007fd4f8684000]是线程栈起始地址。</li>
</ol>
<p>实例二：Waiting on condition 和 TIMED_WAITING<br><img src="/2016/05/31/性能定位整体思路/6.png" alt="waiting图" title="waiting图"></p>
<ol>
<li>“TIMED_WAITING (parking)”中的 timed_waiting 指等待状态，但这里指定了时间，到达指定的时间后自动退出等待状态；parking指线程处于挂起中。</li>
<li>“waiting on condition”需要与堆栈中的“parking to wait for  <0x00000000acd84de8> (a java.util.concurrent.SynchronousQueue$TransferStack)”结合来看。首先，本线程肯定是在等待某个条件的发生，来把自己唤醒。其次，SynchronousQueue 并不是一个队列，只是线程之间移交信息的机制，当我们把一个元素放入到 SynchronousQueue 中时必须有另一个线程正在等待接受移交的任务，因此这就是本线程在等待的条件。</0x00000000acd84de8></li>
</ol>
<p>实例三：in Obejct.wait() 和 TIMED_WAITING<br><img src="/2016/05/31/性能定位整体思路/7.png" alt="objectwaiting图" title="objectwaiting图"></p>
<ol>
<li>“TIMED_WAITING (on object monitor)”，对于本例而言，是因为本线程调用了 java.lang.Object.wait(long timeout) 而进入等待状态。</li>
<li>“Wait Set”中等待的线程状态就是“ in Object.wait() ”。当线程获得了 Monitor，进入了临界区之后，如果发现线程继续运行的条件没有满足，它则调用对象（一般就是被 synchronized 的对象）的 wait() 方法，放弃了 Monitor，进入 “Wait Set”队列。只有当别的线程在该对象上调用了 notify() 或者 notifyAll() ，“ Wait Set”队列中线程才得到机会去竞争，但是只有一个线程获得对象的 Monitor，恢复到运行态。</li>
<li>RMI RenewClean 是 DGCClient 的一部分。DGC 指的是 Distributed GC，即分布式垃圾回收。</li>
</ol>
<h3 id="1-2-机器资源指标"><a href="#1-2-机器资源指标" class="headerlink" title="1.2 机器资源指标"></a>1.2 机器资源指标</h3><p>机器的资源指标可以从机器的CPU、网络、内存、磁盘IO等方面全面系统的监控机器的各个方面。一个有经验的测试人员可以从这些监控命令中获取机器运行的健康情况，从而定位哪里出现了性能瓶颈。Linux下有很多监控命令可以监控到各方面的性能，具体可以参考下图的linux性能监测工具。本文中介绍几种常用的监控工具。<br><img src="/2016/05/31/性能定位整体思路/8.png" alt="linux图" title="linux图"></p>
<h4 id="2-1-1-CPU"><a href="#2-1-1-CPU" class="headerlink" title="2.1.1  CPU"></a>2.1.1  CPU</h4><p>CPU的指标主要用下面两个命令top，mpstat。<br>top：<br><img src="/2016/05/31/性能定位整体思路/9.png" alt="top图" title="top图"></p>
<ol>
<li>红色方框中load表示系统负载（任务队列的平均长度），这三个值分别为1分钟，5分钟，15分钟前到现在的系统负载平均值，一般会小于1，如果持续高于5，要检查是哪个程序影响了系统的运行；一般其数值小于CPU核数，最好不要超过核数的两倍。【  load average数据是每隔5秒钟检查一次活跃的进程数，然后按特定算法计算出的数值，如果这个数除以逻辑CPU的数量的结果高于5，就说明系统在超负荷运转了，可以升级CPU个数】</li>
<li>Tasks——任务（进程），系统现在共有112个进程，其中处于运行中的有1个，111个在休眠状态，stoped状态的有0个，zombie状态（僵尸）的有0个；</li>
<li>%Cpu（s)这一行分别代表：<br>us——用户空间占用CPU百分比(user)；<br>sy——内核空间占用CPU百分比(system)；<br>ni——用户空间内改变过优先级的进程占用CPU百分比(user nice)；<br>id——空闲CPU百分比(idle)；<br>wa——等待输入输出CPU时间百分比(io wait)；<br>hi——CPU服务于硬件中断所耗费的时间总额(hardware irq )；<br>si——CPU服务软中断所耗费的时间总额(software irq)；st——StealTime<br>【若用户使用CPU过多，则需要优化用户程序；若系统内核态使用CPU过多，可能是过多的中断以及上下文切换造成的】</li>
<li>KiB Mem: total——“物理内存总量”、used——“已使用的物理内存”、free——“空闲物理内存”、buffers——“内核缓存内存量”<br>【已使用的物理内存（used）指的是现在系统内核控制的内存数，空闲内存总量（free）是内核还未纳入其管控范围的数量。纳入内核管理的内存不见得都在使用中，还包括过去使用过的现在可以被重复利用的内存，内核并不把这些可被重新使用的内存交还到free中去，因此在linux上free内存会越来越少，但不用为此担心。】</li>
<li>KiB Swap: total——“交换区总量”、used——“已使用交互区总量”、free——空闲交换区总量”、cached——“缓冲的交换区总量”<br>【Swap中的used的数值如果在不断变化，说明内核在不断进行内存和swap的数据交换，内存有可能不够用】</li>
<li>PID:进程ID       </li>
<li>USER: 进程所有者      </li>
<li>PR: 优先级      </li>
<li>NI: nice值（负值表示高优先级，正值表示低优先级）      </li>
<li>VIRT: 进程使用的虚拟内存总量      </li>
<li>RES:进程使用的，未被换出的物理内存大小       </li>
<li>SHR:共享内存大小，单位kb       </li>
<li>S: 进程状态—— D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程     </li>
<li>%CPU: 上次更新到现在的CPU时间占用百分比      </li>
<li>%MEM:进程使用的物理内存百分比       </li>
<li>TIME+:进程使用CPU的总时间       </li>
<li>COMMAND:  命令行  </li>
<li>其他技巧：<br>在top的基本视图中，按键盘数字“1”，可监控每个逻辑CPU的状况；<br>top -p + PID 显示指定的PID进程信息；</li>
</ol>
<p>mpstat：<br>用 mpstat -P -ALL 1   （MultiProcessor Statistics）查看多核CPU每个计算核心的使用情况，主要看idle这个值，这个值越大说明CPU的空闲越大，使用的CPU越小<br><img src="/2016/05/31/性能定位整体思路/10.png" alt="mpstat图" title="mpstat图"></p>
<h4 id="2-1-2-CPU"><a href="#2-1-2-CPU" class="headerlink" title="2.1.2  CPU"></a>2.1.2  CPU</h4><p>sar 全称为System Activity Report，是Unix/Linux 下流行的系统资源监控命令，Linux 下如果没有该命令，需要安装 sysstat 包。sar 在网卡上的监控如下图，按照网卡的设置（有些网卡支持每秒采集一次数据、有些可能需要2秒）实时观察网络流量变化，而且通过 -n ETCP 参数可以把重试、错误、重传、RST包都统计出来。如果网络发生抖动，那么从 retrains/txpck 可以观察到重传率，如下图的红色部分。<br><img src="/2016/05/31/性能定位整体思路/11.png" alt="sar图" title="sar图"><br>用 sar -n DEV 1 【sar：System Activity Recorder】主要负责收集、汇报与存储系统运行信息的，sar命令使用-n DEV 选项可以汇报网络设备相关信息，该条命令主要用来查看网卡信息:<br><img src="/2016/05/31/性能定位整体思路/12.png" alt="sardev图" title="sardev图"></p>
<ol>
<li>FACE：就是网络设备的名称；</li>
<li>rxpck/s：每秒钟接收到的包数目</li>
<li>txpck/s：每秒钟发送出去的包数目</li>
<li>rxbyt/s：每秒钟接收到的字节数</li>
<li>txbyt/s：每秒钟发送出去的字节数</li>
<li>rxcmp/s：每秒钟接收到的压缩包数目</li>
<li>txcmp/s：每秒钟发送出去的压缩包数目</li>
<li>rxmcst/s：每秒钟接收到的多播包的包数目</li>
</ol>
<p>netstat 命令用于显示各种网络相关信息，如网络连接，路由表，接口状态 (Interface Statistics)，masquerade 连接，多播成员 (Multicast Memberships) 等等。在性能测试中，这个命令主要用来查看现有的端口号等等，从整体上看，netstat的输出结果可以分为两个部分：</p>
<ul>
<li>一个是Active Internet connections，称为有源TCP连接，其中”Recv-Q”和”Send-Q”指%0A的是接收队列和发送队列。这些数字一般都应该是0。如果不是则表示软件包正在队列中堆积。这种情况只能在非常少的情况见到。</li>
<li>另一个是Active UNIX domain sockets，称为有源Unix域套接口(和网络套接字一样，但是只能用于本机通信，性能可以提高一倍)。Proto显示连接使用的协议,RefCnt表示连接到本套接口上的进程号,Types显示套接口的类型,State显示套接口当前的状态,Path表示连接到套接口的其它进程使用的路径名。</li>
</ul>
<h4 id="2-1-3-内存"><a href="#2-1-3-内存" class="headerlink" title="2.1.3 内存"></a>2.1.3 内存</h4><p>物理内存和虚拟内存区别：</p>
<ul>
<li>物理内存就是系统硬件提供的内存大小，是真正的内存，相对于物理内存，在linux下还有一个虚拟内存的概念，虚拟内存就是为了满足物理内存的不足而提出的策略，它是利用磁盘空间虚拟出的一块逻辑内存，用作虚拟内存的磁盘空间被称为交换空间（Swap Space）。</li>
<li>作为物理内存的扩展，linux会在物理内存不足时，使用交换分区的虚拟内存，更详细的说，就是内核会将暂时不用的内存块信息写到交换空间，这样以来，物理内存得到了释放，这块内存就可以用于其它目的，当需要用到原始的内容时，这些信息会被重新从交换空间读入物理内存。</li>
</ul>
<p>用 vmstat 1 【Virtual Meomory Statistics（虚拟内存统计）】命令查看内存使用情况：<br><img src="/2016/05/31/性能定位整体思路/13.png" alt="vmstat图" title="vmstat图"><br>其中</p>
<ul>
<li>Procs（进程）：<br>r: 运行队列中进程数量（runnable）；<br>b: 等待IO的进程数量（blocked）</li>
<li>Memory（内存）：<br>swpd: 使用虚拟内存大小；<br>free: 可用内存大小；<br>buff: 用作缓冲的内存大小；<br>cache: 用作缓存的内存大小</li>
<li>Swap：<br>si: 每秒从交换区写到内存的大小；<br>so: 每秒写入交换区的内存大小；<br>【内存够用的时候，这两个值都为0，若这两个值长期大于0时，系统性能会受到影响】<br>IO：（现在的Linux版本块的大小为1024bytes）<br>bi: 每秒读取的块数；<br>bo: 每秒写入的块数;<br>【bi+bo参考值为1000，若超过1000，且wa较大，表示系统IO有问题，应该提高磁盘的读写性能】</li>
<li>system：<br>in: 每秒中断数，包括时钟中断。<br>cs: 每秒上下文切换数。（content switch）<br>【in与cs越大，内核消耗的CPU时间就越多】<br>CPU（以百分比表示）：<br>us: 用户进程执行时间(user time)；<br>sy: 系统进程执行时间(system time)；<br>id: 空闲时间(包括IO等待时间),中央处理器的空闲时间,以百分比表示；<br>wa: 等待IO时间<br>【us+sy参考值为80%，如果大于80%，说明可能存在CPU资源不足的情况】<br>这个命令中主要看参数： r，b，si，so</li>
</ul>
<h4 id="2-1-4-磁盘IO"><a href="#2-1-4-磁盘IO" class="headerlink" title="2.1.4 磁盘IO"></a>2.1.4 磁盘IO</h4><p>用命令 iostat -x 1查看磁盘IO，注意查看%util这个参数<br><img src="/2016/05/31/性能定位整体思路/14.png" alt="iostat图" title="iostat图"></p>
<ul>
<li>rrqm/s:每秒进行merge的读操作数目。即delta(rmerge)/s</li>
<li>wrqm/s:每秒进行merge的写操作数目。即delta(wmerge)/s</li>
<li>r/s:每秒完成的读I/O设备次数。即delta(rio)/s</li>
<li>w/s:每秒完成的写I/0设备次数。即delta(wio)/s</li>
<li>rsec/s:每秒读扇区数。即delta(rsect)/s</li>
<li>wsec/s:每秒写扇区数。即delta(wsect)/s</li>
<li>rKB/s:每秒读K字节数。是rsec/s的一半，因为每扇区大小为512字节</li>
<li>wKB/s:每秒写K字节数。是wsec/s的一半</li>
<li>avgrq-sz:平均每次设备I/O操作的数据大小(扇区)。即delta(rsect+wsect)/delta(rio+wio)</li>
<li>avgqu-sz:平均I/O队列长度。即delta(aveq)/s/1000(因为aveq的单位为毫秒)</li>
<li>await:平均每次设备I/O操作的等待时间(毫秒)。即delta(ruse+wuse)/delta(rio+wio)</li>
<li>svctm:平均每次设备I/O操作的服务时间(毫秒)。即delta(use)/delta(rio+wio)</li>
<li>%util:一秒中有百分之多少的时间用于I/O操作,可以衡量磁盘设备的繁忙程度，或者说一秒中有多少时间I/O队列是非空的。即delta(usr)/s/1000(因为use的单位为毫秒)</li>
</ul>
<p>如果%util接近100%,说明产生的I/O请求太多,I/O系统已经满负载,该磁盘可能存在瓶颈，同时可以结合vmstat查看查看b参数(等待资源的进程数)和wa参数(I/O等待所占用的CPU时间的百分比,高过30%时I/O压力高)。正常情况下svctm应该小于await，而svctm的大小和磁盘性能有关，CPU、内存的负荷也会对svctm值造成影响，过多的请求也会简介导致svctm值的增加。</p>
<p>await的大小一般取决与svctm的值和I/O队列长度以及I/O请求模式。如果svctm与await很接近，表示几乎没有I/O等待，磁盘性能很好；如果await的值远高于svctm的值，表示I/O队列等待太长，系统上运行的应用程序将变慢，此时可以通过更换更快的硬盘来解决问题。</p>
<h3 id="1-3-Nginx端"><a href="#1-3-Nginx端" class="headerlink" title="1.3 Nginx端"></a>1.3 Nginx端</h3><h4 id="1-3-1-查看访问日志access-log、error-log"><a href="#1-3-1-查看访问日志access-log、error-log" class="headerlink" title="1.3.1 查看访问日志access_.log、error.log"></a>1.3.1 查看访问日志access_.log、error.log</h4><p>access.log日志可以在nginx的./conf文件中进行配置，下面是一条详细的access.log日志，通过访问日志和error日志里的有用信息可以粗略定位到哪里出现问题。</p>
<p>10.165.124.21:37444 - - [29/Jan/2016:09:14:01 +0800] “POST /sdk/mobService/device/bd.do HTTP/1.1” 200 51 “-“ “RPT-HTTPClient/0.3-3E” “-“ 1.735 “mobile.service.reg.163.com” “10.165.136.75:8184” “200” “1.735”</p>
<p>每行对应的含义可以参考如下：<br><img src="/2016/05/31/性能定位整体思路/15.png" alt="nginxlog图" title="nginxlog图"><br>要注意区分其中的$request_time和$upstream_response_time：</p>
<ul>
<li>request_time：指的就是从接受用户请求的第一个字节 到发送完响应数据的时间，即包括接收请求数据时间、 程序响应时间、输出；</li>
<li>upstream_response_time：指从Nginx向后端建立连接 开始到接受完数据然后关闭连接为止的时间</li>
<li>总体来说，request_time是包括upstream_response_time时间的，但是如果两者差异太大，可以用netperf工具来查看</li>
</ul>
<h3 id="1-4-Tomcat"><a href="#1-4-Tomcat" class="headerlink" title="1.4. Tomcat"></a>1.4. Tomcat</h3><h4 id="1-4-1-Tomcat日志"><a href="#1-4-1-Tomcat日志" class="headerlink" title="1.4.1 Tomcat日志"></a>1.4.1 Tomcat日志</h4><p>Tomcat默认的引擎为Catalina，host为localhost，所以从tomcat中日志可以查看catalina日志，来确定tomcat的启动是否有报错，localhost_access_log访问日志查看每个请求的状态；<br>用netstat命令来查看网络相关的信息。如果出现404这样的错误，可以查看nginx和tomcat之间的TIME_WAIT数量是否很多，如果TIME_WAIT数量较多，需要进一步来定位问题。</p>
<h4 id="1-4-2-JVM监控"><a href="#1-4-2-JVM监控" class="headerlink" title="1.4.2 JVM监控"></a>1.4.2 JVM监控</h4><p>JVM的监控在性能测试中非常重要，采用工具对JVM监控并分析监控结果可以得到很多定位问题的有用信息，下图是JVM定位问题时经常需要关注的指标和各个指标之间的关系：<br><img src="/2016/05/31/性能定位整体思路/16.png" alt="jmx图" title="jmx图"><br>针对Tomcat这样的后端服务器的JVM监控，可以采用如下设置。在目录/home/appuser/urs/urs-mobile-bj-perf/tomcat-urs-mobile-perf-Ins1/default中配置jvm的参数（根据自己应用的具体目录而定），一般加上如下两行：<br>   -Dcom.sun.management.jmxremote.port=8013 \<br>   -Djava.rmi.server.hostname=10.165.124.14 \</p>
<p>Jvm中监控的参数主要包括如下几个方面：</p>
<ol>
<li>CPU及堆内存监控<br>主要是查看CPU使用率和堆内存的使用情况，CPU使用情况可以用来判断当前测试的接口大体的CPU资源使用情况，堆内存可以看到当前JVM分配的最大可用内存和已用内存趋势。<br>如果CPU使用率过高，TPS比较低，或者响应时间比较长，可以通过查看线程状态，生成线程dump进行分析，也有可能是达到应用服务器的瓶颈。堆内存可以判断垃圾回收是否正常，如果发现堆内存使用急剧上升时，也可以用堆dump把当前堆内存的使用情况保存下来进行查看。如果CPU波动比较明显，GC的开销占比比较高，同时监控到堆使用状态异常，转向内存的监控和定位。</li>
<li>线程监控<br>线程选项卡主要是查看当前有没有被阻塞的线程，看一下block和wait的线程情况，并用线程堆栈信息辅助查看线程block的具体位置。<br>线程dump可以查看线程的状态，看是在等待、运行、阻塞的状态，并通过下面的堆栈信息来进一步定位造成线程等待或者阻塞的原因。</li>
<li>热点方法监控<br>对CPU进行抽样，查看自用时间以及自用时间CPU，对于占用CPU较多的，可以进一步使用javosize进行定位。切换到线程CPU时间下面监控线程CPU时间。</li>
<li>装入的类<br>监控装入的类和卸载的类的变化情况，一般情况下，应用运行一段时间后，装入的类的总数基本保持不变，如果总数一直在增加，需要关注下perm区。</li>
<li>jvm常用调优命令<br>jps ，主要用来输出JVM中运行的进程状态信息；<br>jstack，java堆栈跟踪工具；<br>jstat，虚拟机统计信息监视工具；<br>jinfo，java配置信息工具；<br>jmap，java内存映像工具；<br>jhat，虚拟机堆转储快照分析工具；<br>VisualVM，可视化的监控工具</li>
</ol>
<h2 id="二、常见服务器错误"><a href="#二、常见服务器错误" class="headerlink" title="二、常见服务器错误"></a>二、常见服务器错误</h2><h3 id="2-1-404-错误"><a href="#2-1-404-错误" class="headerlink" title="2.1 404 错误"></a>2.1 404 错误</h3><p>一般是因为nginx和后端的连接出现了问题，没有正常连接起来。通常检查思路可以分为如下：</p>
<ol>
<li>nginx配置的upstream的端口号是否有误：查看omad上的端口号，以及在服务器上用netstat 命令查看端口号和对应的PID是否一致；<br>命令： netstata –anp|grep 端口号<br>   lsof –I : 8181  查看8181端口是否被占用</li>
<li>查看后端应用是否启动起来；<br>命令： ps –ef |grep tomcat； ps –ef |grep resin；等等</li>
<li>查看nginx端和tomcat端的日志，确定数据库，nkv等是否正常连接；</li>
<li>tomcat启动成功，但是context启动失败，解决办法就是增加在目录/WEB-INF/classes中增加启动日志查看context的启动；</li>
<li>如果是本地访问，确认localhost是否正确配置，一般来说配置nginx的私有ip地址加域名；</li>
<li>tomcat和压测机器的/etc/hosts是否有回调到nginx上去，如果是同一个租户配置私有ip地址，若跨租户要配置为机房网络ip；</li>
<li>配置好了nginx的.conf文件后，访问相应的域名出来的是“404，not found nginx”，去查看nginx的日志，看是否是缺失某些文件</li>
</ol>
<h3 id="2-2-Nginx-500-错误"><a href="#2-2-Nginx-500-错误" class="headerlink" title="2.2 Nginx 500 错误"></a>2.2 Nginx 500 错误</h3><p>如果遇到nginx 出现500错误，根本原因是服务器出现了未捕捉的异常，有两种情况：</p>
<ol>
<li>客户端只返回Internal Service Error，一般是 nginx 错误，查看nginx 的error日志</li>
<li>客户端有完整堆栈信息，一般是upstream 出现未捕捉的异常，此时 nginx error无日志、upstream的应用容器一般有错误日志，可以查看：<br>应用出现运行时错误，比如常见的空指针错误、数组越界等<br>依赖服务异常，应用没有处理，引发运行时错误（比如调用其他服务API，当其他服务部可用可能返回null，但是应用未考虑这种情况，依然进行方法调用引发空指针错误）</li>
</ol>
<h3 id="2-3-Nginx-502-错误"><a href="#2-3-Nginx-502-错误" class="headerlink" title="2.3 Nginx 502 错误"></a>2.3 Nginx 502 错误</h3><p>Nginx 502 错误即Bad Gateway，其原因也分成nginx本身和后端应用，主要有以下几种情况：</p>
<ol>
<li>Nginx本身， 没有给upstream设置 DNS，一般错误日志会有：” no resolver defined to resolve”</li>
<li>Nginx 本身，无法解析upstream 域名，一般错误日志会有：“could not be resolved”</li>
<li>应用挂掉，导致nginx 连接出现连接拒绝；</li>
<li>服务刚启动，启动期间，端口还未监听，或者端口已监听但是应用未启动完成，导致连接拒绝；</li>
<li>突然大批量请求达到，Socket backlog（全连接队列）满，可能会导致内核返回RST，引发连接拒绝；</li>
<li>使用连接线程池，当更新线程/线程重建时，有大批量连接到达导致线程不够用，引发连接拒绝（底层原因同5）；</li>
<li>应用过载，应用容器会关闭一部分连接，一般nginx日志中会有“upstream prematurely closed connection”；</li>
<li>其他nginx执行读取时出现的失败，错误日志会出现“readv() failed”信息。</li>
</ol>
<h3 id="2-4-Nginx-504错误"><a href="#2-4-Nginx-504错误" class="headerlink" title="2.4 Nginx 504错误"></a>2.4 Nginx 504错误</h3><p>Nginx 504 错误即 Gateway Time-out，其主要原因是 nginx到upstream出现 Connection timeout、write/read timeout。</p>
<ol>
<li>Nginx到应用服务器网络不通，检查nginx到应用服务器的网络，包括路由是否正确，如果不同租户，要检查租户间的ACL是否设置等</li>
<li>Nginx写入到应用服务器写超时，常见是应用服务器繁忙且分布不出新的工作线程，backlog满了无法新建新连接，后续握手包被应用服务器内核丢弃</li>
<li>Nginx读取应用服务器读取超时，一般是应用服务器的响应时间超过Nginx设置的超时</li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<p>一个请求从客户端发起到最后在数据库中进行查询，中间经历了很多个环节。本文就是针对出现的问题，快速定位到是哪个步骤环节出现了问题，由于笔者也在不断的学习中，希望有问题大家能提出来共同进行学习。</p>
<h2 id="一、服务器定位"><a href="#一、服务器定位" c]]>
    </summary>
    
      <category term="架构" scheme="http://yoursite.com/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="性能测试" scheme="http://yoursite.com/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[ELK构建日志搜索服务]]></title>
    <link href="http://yoursite.com/2016/05/30/ELK%E6%9E%84%E5%BB%BA%E6%97%A5%E5%BF%97%E6%90%9C%E7%B4%A2%E6%9C%8D/"/>
    <id>http://yoursite.com/2016/05/30/ELK构建日志搜索服/</id>
    <published>2016-05-30T09:59:02.000Z</published>
    <updated>2016-05-31T04:54:27.000Z</updated>
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>我们知道所有的网站、互联网应用、后台服务和其他复杂的IT基础设施每时每刻都在生成大量的数据，这些数据结构化不明显且多种多样，采用传统方法不容易或不能及时处理和分析。这种程序、机器生成的数据可以捕获用户行为、安全风险、运行状态、服务水平、客户体验等关键信息。这是它成为增长最快、最复杂和最有价值的一种大数据的原因。如何改变组织使用数据的方式，帮助这些数据释放隐藏于其中的巨大价值，使程序、机器的日志数据对每个用户来说触手可及、随时可用并展示价值。这正是日志搜索服务所专注的地方。</p>
<h2 id="日志搜索服务的应用场景"><a href="#日志搜索服务的应用场景" class="headerlink" title="日志搜索服务的应用场景"></a>日志搜索服务的应用场景</h2><p>日志搜索服务能够分布式的采集用户日志信息，集中到一个地方统一处理。经过智能化的解析日志格式，挖掘日志中隐藏的数据特性。再通过准实时的分词和索引，提供给用户近实时的结果分析查看，及自由的关键字查询和多样化的统计、分析功能。用户使用日志搜索服务将能方便的对自己的业务进行监控、统计分析、及安全与合规审计。<br>几种常见的日志搜索应用场景如下：<br>  服务程序bug分析<br>    1.快速定位发现程序日志错误或异常<br>    2.关联分析大规模分布式系统各个模块产生的大量Debug日志<br>  运维可用性监控及应用性能监控<br>    1.通过日志对服务器及应用程序状态实时监控<br>    2.通过日志对应用程序性能实时监控，及时发现性能瓶颈<br>    3.安全信息与事件管理<br>  网站用户及手机用户访问统计<br>    1.社交、视频、电商、游戏网站用户行为及交易行为分析<br>    2.客户端设备、操作系统、浏览器统计</p>
<h2 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h2> <img src="/2016/05/30/ELK构建日志搜索服/1.png" alt="整体架构图" title="整体架构图">
<p> 按照日志处理的流程，我们将整个日志搜索服务系统分成4部分。如上图所示，依次为日志搜集部分、日志格式解析部分、索引/存储部分和可视化/搜索部分。<br> 各个部分遵循先后顺序，依次对日志数据数据流进行处理。并且每个部分都被完整的赋予了实现某个特定的功能。<br> 下面是对各个部分详细的介绍。</p>
<h2 id="日志搜集"><a href="#日志搜集" class="headerlink" title="日志搜集"></a>日志搜集</h2><p>日志收集模块负责从用户的服务器节点上收集原始日志数据，并统一转发至RabbitMQ/Kafka队列，以便后续模块处理。日志的收集任务由杭研自主研发的Datastream服务负责完成。Datastream Agent支持监控整个目录及Rotated文件的功能，并支持全量与增量拉取文件数据。而且其自身提供了将数据转发至RabbitMQ/Kafka的选项。<br><img src="/2016/05/30/ELK构建日志搜索服/2.png" alt="日志搜集图" title="日志搜集图"><br>RabbitMQ/Kafka队列用于集中化和缓存Datasteam Agent搜集到的数据，以便后续处理程序从中拉取。</p>
<h2 id="ETL解析"><a href="#ETL解析" class="headerlink" title="ETL解析"></a>ETL解析</h2><p>格式解析用于将半结构化的日志数据解析为格式化的日志信息。格式解析是日志数据可用于后续高级分析、统计的基础，解析后的日志各个字段也是后续统计、分析功能的基本维度。<br>举个例子，一条最常见的Nginx访问日志：<br>61.135.255.84 - - [21/Apr/2015:14:05:00 +0800] “GET /sd/service/query?index=ndirServiceZixunTopic&amp;stype=1&amp;offset=0&amp;length=15&amp;q=%E5%BD%A9%E7%A5%A8 HTTP/1.1” 200 237 0.010 “10.120.150.115:7982” 0.010<br>通常可以解析成：<br><img src="/2016/05/30/ELK构建日志搜索服/3.png" alt="日志搜集图" title="日志搜集图"><br>此时，用户即可以根据解析结果进行更有目的的搜索（或统计），诸如：统计status非200的请求条数，或响应时间超过500ms的请求数等等。<br>对于无法准确解析出字段信息的日志，我们按整体数据作为一个默认字段来进行索引（仍然可以进行搜索，但无法完成更高级的统计分析操作）。<br>日志格式的解析功能采用Logstash开源组件实现。目前，通用的日志解析方法主要依赖于正则表达式来实现。</p>
<h2 id="索引-存储"><a href="#索引-存储" class="headerlink" title="索引/存储"></a>索引/存储</h2><p>索引和存储模块最主要的功能是将解析后的日志数据建成索引，并提供近实时的搜索服务。日志数据在被建成索引后用户即可以按关键字进行搜索，或进行统计、分析。<br>索引/存储模块由开源的搜索系统Elasticsearch实现。Elasticsearch基于成熟的信息检索框架Lucene，具有近实时搜索、高度支持分布式、索引格式自由、支持多索引等优点，并针对日志搜索、日志统计分析的场景进行了特殊的优化，非常适合用于日志检索服务。<br>但要实现高性能、服务可靠的搜索服务系统，也需要针对特定的场景对Elasticsearch进行适当的优化。</p>
<ul>
<li>集群的构建<br>索引/存储集群的部署最好采用设置客户端节点、数据节点、Master节点的方式，实现功能管理和数据管理分离。<br>客户端节点主要用于与集群外部模块进行交互。接收前端的搜索请求和索引请求，并将请求均衡分发至数据处理节点。客户端节点还可以承担批量数据拆分和搜索结果合并等任务，使后端数据节点专注于搜索、索引等数据处理，减轻数据节点压力。多个客户端节点之前可架设Nginx代理服务器进行轮询均衡。<br>数据节点负责数据的存储、索引和搜索。是集群中规模最大的部分，集群的扩容、缩容服务主要在数据节点上进行。集群的数据节点将会屏蔽HTTP服务，无法接收到外部用户的请求，以保持对数据处理的专注。<br>Master节点负责用于整个集群事务的管理，包括集群的状态监控、接受新节点的加入/离开，集群节点间的数据均衡等。</li>
<li>预防脑裂现象<br>通常，一个集群至少需要设置3个Master节点，用于Master节点的高可用及Leader选举。集群需要设置一个最小Master节点数，通常为Master节点数/2+1。当Master总数小于此值时，集群不能推举选出Leader节点，用于防止集群脑裂（Split Brain）发生，即部分节点网络丢失后重新集结成新的集群。</li>
<li>单播/多播<br>集群节点间的发现可以采用单播（Unicast）也可以采用多播（Multicast），多播通常更方便，但在生产环境应用时，当集群节点数增加，多播可能会产生较大的网络负担，并且多播较易和其他产品节点互串，因此应当禁止多播模式，采用单播节点发现。设置单播配置需要配置所有Master节点地址，其他节点信息可自动从Master节点处获取。</li>
<li>自动恢复设置<br>集群的自动数据恢复需要设置一个最低节点数N，即只有当集群中存在N个以上节点时才能进行数据恢复。并可以再额外设置期望节点数和恢复等待时间，也即最好是达到期望的节点数（通常是整个集群节点）了或已经达到最低节点数并已经等待恢复等待时间后再进行恢复。以避免集群中当一个节点进行重启或集群进行整体重启/更新等操作时，Master误以为节点离线而迅速进行节点数据恢复（产生大量的节点间数据误拷贝操作）。</li>
<li>高可用/高可靠<br>集群的高可用/高可靠由节点副本功能提供。</li>
<li>其他 还有集群的安全性设置和针对日志搜索的场景通常写请求量大而读请求量小可进行针对性的写请求优化等。</li>
</ul>
<p>整个索引/存储的集群构成类似于下图：<br><img src="/2016/05/30/ELK构建日志搜索服/4.png" alt="索引存储集群图" title="索引存储集群图"></p>
<h2 id="可视化-搜索"><a href="#可视化-搜索" class="headerlink" title="可视化/搜索"></a>可视化/搜索</h2><p>可视化/搜索部分作为用户的入口，提供搜索并直观的展示用户搜索结果功能，并且用户可以对搜索结果进行统计分析和报表等展示。对于用户来说，通常可能并不需要了解整个系统底层的实现，而只需要熟悉可视化/搜索部分功能模块，方便的使用相关功能满足自己的业务需求。<br>日志搜索系统的可视化/搜索功能采用开源Kibana组件实现。Kibana目前提供可视化报表种类有：</p>
<ul>
<li>历史趋势图</li>
<li>表格</li>
<li>地图</li>
<li>terms统计</li>
<li>query统计</li>
<li>hits统计<br>等。并且支持对结果以时间折线图、条形图、饼状图等图形进行展示。<br>可视化效果示例：<img src="/2016/05/30/ELK构建日志搜索服/5.png" alt="可视化搜索图" title="可视化搜索图">
</li>
</ul>
<h2 id="其他功能"><a href="#其他功能" class="headerlink" title="其他功能"></a>其他功能</h2><p>对于日志搜索服务系统的管理，还需提供管理服务器模块，用于管理日志搜索系统的创建、删除、修改、扩容等操作，用户可以方便的接入日志搜索服务系统，并无需关心系统的运维工作。<br>此外也要提供完善的报警监控功能，诸如进程、节点、服务状态、系统负载等多维度的监控，保障服务的稳定运行。用户将能够享受到最便捷的日志搜索服务。</p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>我们知道所有的网站、互联网应用、后台服务和其他复杂的IT基础设施每时每刻都在生成大量的数据，这些数据结构化不明显且多种多样，采用传统方法不容]]>
    </summary>
    
      <category term="ELK" scheme="http://yoursite.com/tags/ELK/"/>
    
      <category term="日志搜索" scheme="http://yoursite.com/tags/%E6%97%A5%E5%BF%97%E6%90%9C%E7%B4%A2/"/>
    
  </entry>
  
</feed>
